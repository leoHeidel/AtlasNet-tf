{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lavavu-osmesa\n",
    "#git clone git@github.com:mmatl/pyopengl.git\n",
    "#pip install ./pyopenglShapeNetVox32/02691156/870dc1667e957672c66e7238ddb322f4/model.binvox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACACAYAAACoX7ryAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEqklEQVR4nO3aT2tddR7H8c+5+Vdz06S3BZEiThkdIta09ZaO0nVx7ZPowoXo1vU4C2EI4qZPYR5AYR5AwVroHwUX4sxAoY2N2lSTTFua9N4zu8JgaccEv8fU12uZs8hn8eOdw8mvads2ANTodT0A4PdEdAEKiS5AIdEFKCS6AIVEF6DQ5FOeu0/Gr63p6Pc62/zaHnu2vekCFBJdgEKiC1BIdAEKiS5AIdEFKCS6AIVEF6CQ6AIUEl2AQqILUEh0AQqJLkAh0QUoJLoAhUQXoJDoAhQSXYBCogtQSHQBCokuQCHRBSgkugCFRBegkOgCFBJdgEKiC1BIdAEKiS5AIdEFKCS6AIVEF6CQ6AIUEl2AQqILUEh0AQqJLkAh0QUoJLoAhUQXoJDoAhQSXYBCogtQSHQBCokuQCHRBSgkugCFRBegkOgCFBJdgEKiC1BosusBe13btlm9uZJvrn2Z7fE4/f3789rweOYPHEjTNF3Pg125ceNGrl69mq2trSwsLOTUqVMZDAZdz9rTRHcX2rbNlxc+y6fvvpvvv/s267NzSTOZ1195Le//7aMsnlgSXvasCxcu5OzZs7l169ajczwcDrO8vJwTJ050O24Pa9q2fdLzJz78vVu9uZIP33k7/7pxJ99uvpzxxHOZnPwpz2+t5uTJN/LxP/6e5/qzXc/8revqr5Kz/QQrKys5c+ZM1tbWMjs7m6Zp8vDhw2xubmY4HOb8+fOZnXW2n+KxZ9s33V345osvsvLD97l599WMHhxOe+9QRvf+mB+nBvn68pV89fnlrifCjly7di2rq6vp9/uZmJhIr9fL9PR05ubmcuXKlVy6dKnriXuW6O7CaDzK5mYvvXZfJqab9HpNepnKzPR82uZB7q1vdD0RdmRraytJfvZ5rNfrZTweZ319vYtZzwTR3YXZ+fns60+knb6dZjxOr9embbYyOf4u+/ZP5dCLL3Q9EXZkYWEhSTIajf7n59vb25mamsrhw4e7mPVM8I+0XXj1+PG89PIfcvuf/87t0U+ZGc3k0Mx/cnBqIy+88WZeWvxT1xNhR4bDYY4cOZLr16+n3++naZpsb2/n/v37OXbsWBYXF7ueuGd5092F+QMH8sHHn+TY4lLmcydzo5X0Hmzk+cWTee8vf83++fmuJ8KODAaDnDt3LkePHs3GxkbW19dz9+7dLC0tZXl5+dGbML+c2wu71LZtfrxzJ5c/v5TR9sPMTE9n+NafszAYuC72/3F74TdsbW0tFy9efPRZ4fTp0zl48GDXs/aKx55t0aVrosuzypUxgK6JLkAh0QUoJLoAhUQXoJDoAhQSXYBCogtQSHQBCokuQCHRBSgkugCFRBegkOgCFBJdgEKiC1BIdAEKiS5AIdEFKCS6AIVEF6CQ6AIUEl2AQqILUEh0AQqJLkAh0QUoJLoAhUQXoJDoAhQSXYBCogtQSHQBCokuQCHRBSgkugCFRBegkOgCFBJdgEKiC1BIdAEKiS5AIdEFKCS6AIVEF6CQ6AIUEl2AQqILUEh0AQqJLkAh0QUoJLoAhSaf8rwpWQH1nG064U0XoJDoAhQSXYBCogtQSHQBCokuQKH/AvN335rmCqRgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render offscreen -- make sure to set the PyOpenGL platform\n",
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\"\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "\n",
    "fuze_trimesh = trimesh.load('data/test_obj/fuze.obj')\n",
    "mesh = pyrender.Mesh.from_trimesh(fuze_trimesh)\n",
    "scene = pyrender.Scene()\n",
    "scene.add(mesh)\n",
    "\n",
    "# Set up the camera -- z-axis away from the scene, x-axis right, y-axis up\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "s = np.sqrt(2)/2\n",
    "camera_pose = np.array([\n",
    "       [0.0, -s,   s,   0.3],\n",
    "       [1.0,  0.0, 0.0, 0.0],\n",
    "       [0.0,  s,   s,   0.35],\n",
    "       [0.0,  0.0, 0.0, 1.0],\n",
    "    ])\n",
    "scene.add(camera, pose=camera_pose)\n",
    "\n",
    "# Set up the light -- a single spot light in the same spot as the camera\n",
    "light = pyrender.SpotLight(color=np.ones(3), intensity=3.0,\n",
    "                               innerConeAngle=np.pi/16.0)\n",
    "scene.add(light, pose=camera_pose)\n",
    "\n",
    "# Render the scene\n",
    "r = pyrender.OffscreenRenderer(640, 480)\n",
    "color, depth = r.render(scene)\n",
    "\n",
    "# Show the images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis('off')\n",
    "plt.imshow(color)\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis('off')\n",
    "plt.imshow(depth, cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_around_center(theta=0, phi=np.pi/2, dist=0):\n",
    "    rot_matrix_theta = np.array([\n",
    "        [np.cos(theta), 0, np.sin(theta)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(theta), 0, np.cos(theta)]\n",
    "    ])\n",
    "    rot_matrix_phi = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.sin(phi), np.cos(phi)],\n",
    "        [0, -np.cos(phi), np.sin(phi)]\n",
    "    ])\n",
    "    rot_matrix = rot_matrix_theta@rot_matrix_phi\n",
    "    uz = np.array([0,0,1])\n",
    "    start_pos = rot_matrix @ uz\n",
    "    camera = np.zeros((4,4), dtype=np.float32)\n",
    "    inv = np.array([\n",
    "        [-1,0,0],\n",
    "        [0,1,0],\n",
    "        [0,0,-1]\n",
    "    ])\n",
    "    camera[:3,3] = inv @ uz\n",
    "    camera[:3,:3] =  inv @ rot_matrix.T\n",
    "    camera[3,3] = 1\n",
    "    return camera\n",
    "\n",
    "mat = camera_around_center(theta=np.pi / 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render offscreen -- make sure to set the PyOpenGL platform\n",
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\"\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import pyrender\n",
    "\n",
    "# Load the FUZE bottle trimesh and put it in a scene\n",
    "fuze_trimesh = trimesh.load('/Data/leo/download/ShapeNetCore.v2/02691156/873f4d2e92681d12709eb7790ef48e0c/models/model_normalized.obj')\n",
    "#mesh = pyrender.Mesh.from_trimesh(fuze_trimesh)\n",
    "scene = pyrender.Scene.from_trimesh_scene(fuze_trimesh)\n",
    "#scene = pyrender.Scene()\n",
    "#scene.add(mesh)\n",
    "\n",
    "# Set up the camera -- z-axis away from the scene, x-axis right, y-axis up\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "s = np.sqrt(2)/2\n",
    "camera_pose = mat\n",
    "scene.add(camera, pose=camera_pose)\n",
    "\n",
    "# Set up the light -- a single spot light in the same spot as the camera\n",
    "light = pyrender.SpotLight(color=np.ones(3), intensity=3.0,\n",
    "                               innerConeAngle=np.pi/16.0)\n",
    "scene.add(light, pose=camera_pose)\n",
    "\n",
    "# Render the scene\n",
    "r = pyrender.OffscreenRenderer(512, 512)\n",
    "color, depth = r.render(scene)\n",
    "\n",
    "# Show the images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis('off')\n",
    "plt.imshow(color)\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis('off')\n",
    "plt.imshow(depth, cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis('off')\n",
    "plt.imshow(color)\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis('off')\n",
    "plt.imshow(depth, cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "class Voxels(object):\n",
    "    \"\"\" Holds a binvox model.\n",
    "    data is either a three-dimensional numpy boolean array (dense representation)\n",
    "    or a two-dimensional numpy float array (coordinate representation).\n",
    "    dims, translate and scale are the model metadata.\n",
    "    dims are the voxel dimensions, e.g. [32, 32, 32] for a 32x32x32 model.\n",
    "    scale and translate relate the voxels to the original model coordinates.\n",
    "    To translate voxel coordinates i, j, k to original coordinates x, y, z:\n",
    "    x_n = (i+.5)/dims[0]\n",
    "    y_n = (j+.5)/dims[1]\n",
    "    z_n = (k+.5)/dims[2]\n",
    "    x = scale*x_n + translate[0]\n",
    "    y = scale*y_n + translate[1]\n",
    "    z = scale*z_n + translate[2]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, dims, translate, scale, axis_order):\n",
    "        self.data = data\n",
    "        self.dims = dims\n",
    "        self.translate = translate\n",
    "        self.scale = scale\n",
    "        assert (axis_order in ('xzy', 'xyz'))\n",
    "        self.axis_order = axis_order\n",
    "\n",
    "    def clone(self):\n",
    "        data = self.data.copy()\n",
    "        dims = self.dims[:]\n",
    "        translate = self.translate[:]\n",
    "        return Voxels(data, dims, translate, self.scale, self.axis_order)\n",
    "\n",
    "    def write(self, fp):\n",
    "        write(self, fp)\n",
    "\n",
    "def read_header(fp):\n",
    "    \"\"\" Read binvox header. Mostly meant for internal use.\n",
    "    \"\"\"\n",
    "    line = fp.readline().strip()\n",
    "    if not line.startswith(b'#binvox'):\n",
    "        raise IOError('Not a binvox file')\n",
    "    dims = list(map(int, fp.readline().strip().split(b' ')[1:]))\n",
    "    translate = list(map(float, fp.readline().strip().split(b' ')[1:]))\n",
    "    scale = list(map(float, fp.readline().strip().split(b' ')[1:]))[0]\n",
    "    line = fp.readline()\n",
    "    return dims, translate, scale\n",
    "\n",
    "def read_as_3d_array(fp, fix_coords=True):\n",
    "    \"\"\" Read binary binvox format as array.\n",
    "    Returns the model with accompanying metadata.\n",
    "    Voxels are stored in a three-dimensional numpy array, which is simple and\n",
    "    direct, but may use a lot of memory for large models. (Storage requirements\n",
    "    are 8*(d^3) bytes, where d is the dimensions of the binvox model. Numpy\n",
    "    boolean arrays use a byte per element).\n",
    "    Doesn't do any checks on input except for the '#binvox' line.\n",
    "    \"\"\"\n",
    "    dims, translate, scale = read_header(fp)\n",
    "    raw_data = np.frombuffer(fp.read(), dtype=np.uint8)\n",
    "    # if just using reshape() on the raw data:\n",
    "    # indexing the array as array[i,j,k], the indices map into the\n",
    "    # coords as:\n",
    "    # i -> x\n",
    "    # j -> z\n",
    "    # k -> y\n",
    "    # if fix_coords is true, then data is rearranged so that\n",
    "    # mapping is\n",
    "    # i -> x\n",
    "    # j -> y\n",
    "    # k -> z\n",
    "    values, counts = raw_data[::2], raw_data[1::2]\n",
    "    data = np.repeat(values, counts).astype(np.bool)\n",
    "    data = data.reshape(dims)\n",
    "    if fix_coords:\n",
    "        # xzy to xyz TODO the right thing\n",
    "        data = np.transpose(data, (0, 2, 1))\n",
    "        axis_order = 'xyz'\n",
    "    else:\n",
    "        axis_order = 'xzy'\n",
    "    return Voxels(data, dims, translate, scale, axis_order)\n",
    "\n",
    "def read_as_coord_array(fp, fix_coords=True):\n",
    "    \"\"\" Read binary binvox format as coordinates.\n",
    "    Returns binvox model with voxels in a \"coordinate\" representation, i.e.  an\n",
    "    3 x N array where N is the number of nonzero voxels. Each column\n",
    "    corresponds to a nonzero voxel and the 3 rows are the (x, z, y) coordinates\n",
    "    of the voxel.  (The odd ordering is due to the way binvox format lays out\n",
    "    data).  Note that coordinates refer to the binvox voxels, without any\n",
    "    scaling or translation.\n",
    "    Use this to save memory if your model is very sparse (mostly empty).\n",
    "    Doesn't do any checks on input except for the '#binvox' line.\n",
    "    \"\"\"\n",
    "    dims, translate, scale = read_header(fp)\n",
    "    raw_data = np.frombuffer(fp.read(), dtype=np.uint8)\n",
    "\n",
    "    values, counts = raw_data[::2], raw_data[1::2]\n",
    "\n",
    "    sz = np.prod(dims)\n",
    "    index, end_index = 0, 0\n",
    "    end_indices = np.cumsum(counts)\n",
    "    indices = np.concatenate(([0], end_indices[:-1])).astype(end_indices.dtype)\n",
    "\n",
    "    values = values.astype(np.bool)\n",
    "    indices = indices[values]\n",
    "    end_indices = end_indices[values]\n",
    "\n",
    "    nz_voxels = []\n",
    "    for index, end_index in zip(indices, end_indices):\n",
    "        nz_voxels.extend(range(index, end_index))\n",
    "    nz_voxels = np.array(nz_voxels)\n",
    "    # TODO are these dims correct?\n",
    "    # according to docs,\n",
    "    # index = x * wxh + z * width + y; // wxh = width * height = d * d\n",
    "\n",
    "    x = nz_voxels / (dims[0]*dims[1])\n",
    "    zwpy = nz_voxels % (dims[0]*dims[1]) # z*w + y\n",
    "    z = zwpy / dims[0]\n",
    "    y = zwpy % dims[0]\n",
    "    if fix_coords:\n",
    "        data = np.vstack((x, y, z))\n",
    "        axis_order = 'xyz'\n",
    "    else:\n",
    "        data = np.vstack((x, z, y))\n",
    "        axis_order = 'xzy'\n",
    "\n",
    "    #return Voxels(data, dims, translate, scale, axis_order)\n",
    "    return Voxels(np.ascontiguousarray(data), dims, translate, scale, axis_order)\n",
    "\n",
    "def dense_to_sparse(voxel_data, dtype=np.int):\n",
    "    \"\"\" From dense representation to sparse (coordinate) representation.\n",
    "    No coordinate reordering.\n",
    "    \"\"\"\n",
    "    if voxel_data.ndim!=3:\n",
    "        raise ValueError('voxel_data is wrong shape; should be 3D array.')\n",
    "    return np.asarray(np.nonzero(voxel_data), dtype)\n",
    "\n",
    "def sparse_to_dense(voxel_data, dims, dtype=np.bool):\n",
    "    if voxel_data.ndim!=2 or voxel_data.shape[0]!=3:\n",
    "        raise ValueError('voxel_data is wrong shape; should be 3xN array.')\n",
    "    if np.isscalar(dims):\n",
    "        dims = [dims]*3\n",
    "    dims = np.atleast_2d(dims).T\n",
    "    # truncate to integers\n",
    "    xyz = voxel_data.astype(np.int)\n",
    "    # discard voxels that fall outside dims\n",
    "    valid_ix = ~np.any((xyz < 0) | (xyz >= dims), 0)\n",
    "    xyz = xyz[:,valid_ix]\n",
    "    out = np.zeros(dims.flatten(), dtype=dtype)\n",
    "    out[tuple(xyz)] = True\n",
    "    return out\n",
    "\n",
    "#def get_linear_index(x, y, z, dims):\n",
    "    #\"\"\" Assuming xzy order. (y increasing fastest.\n",
    "    #TODO ensure this is right when dims are not all same\n",
    "    #\"\"\"\n",
    "    #return x*(dims[1]*dims[2]) + z*dims[1] + y\n",
    "\n",
    "def write(voxel_model, fp):\n",
    "    \"\"\" Write binary binvox format.\n",
    "    Note that when saving a model in sparse (coordinate) format, it is first\n",
    "    converted to dense format.\n",
    "    Doesn't check if the model is 'sane'.\n",
    "    \"\"\"\n",
    "    if voxel_model.data.ndim==2:\n",
    "        # TODO avoid conversion to dense\n",
    "        dense_voxel_data = sparse_to_dense(voxel_model.data, voxel_model.dims)\n",
    "    else:\n",
    "        dense_voxel_data = voxel_model.data\n",
    "\n",
    "    fp.write('#binvox 1\\n')\n",
    "    fp.write('dim '+' '.join(map(str, voxel_model.dims))+'\\n')\n",
    "    fp.write('translate '+' '.join(map(str, voxel_model.translate))+'\\n')\n",
    "    fp.write('scale '+str(voxel_model.scale)+'\\n')\n",
    "    fp.write('data\\n')\n",
    "    if not voxel_model.axis_order in ('xzy', 'xyz'):\n",
    "        raise ValueError('Unsupported voxel model axis order')\n",
    "\n",
    "    if voxel_model.axis_order=='xzy':\n",
    "        voxels_flat = dense_voxel_data.flatten()\n",
    "    elif voxel_model.axis_order=='xyz':\n",
    "        voxels_flat = np.transpose(dense_voxel_data, (0, 2, 1)).flatten()\n",
    "\n",
    "    # keep a sort of state machine for writing run length encoding\n",
    "    state = voxels_flat[0]\n",
    "    ctr = 0\n",
    "    for c in voxels_flat:\n",
    "        if c==state:\n",
    "            ctr += 1\n",
    "            # if ctr hits max, dump\n",
    "            if ctr==255:\n",
    "                fp.write(chr(state))\n",
    "                fp.write(chr(ctr))\n",
    "                ctr = 0\n",
    "        else:\n",
    "            # if switch state, dump\n",
    "            fp.write(chr(state))\n",
    "            fp.write(chr(ctr))\n",
    "            state = c\n",
    "            ctr = 1\n",
    "    # flush out remainders\n",
    "    if ctr > 0:\n",
    "        fp.write(chr(state))\n",
    "        fp.write(chr(ctr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_obj\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"ShapeNetVox32/02691156/870dc1667e957672c66e7238ddb322f4/model.binvox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = read_as_coord_array(open(model_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 711)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
